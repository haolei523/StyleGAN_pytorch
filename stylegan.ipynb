{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bd2ff6",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "190c6d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T06:21:53.015726Z",
     "start_time": "2021-10-24T06:21:53.010176Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from io import BytesIO\n",
    "import lmdb\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "# from torchvision.utils import make_grid\n",
    "# from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1db1d4",
   "metadata": {},
   "source": [
    "## Dataset Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837ed530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:35.830622Z",
     "start_time": "2021-10-24T05:21:35.761625Z"
    }
   },
   "outputs": [],
   "source": [
    "class AnimeFace(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        root_folder='/amax/data/LHao/dataset/', \n",
    "        transform=None, \n",
    "        sizes=(4, 8, 16, 32, 64), \n",
    "        db_path='./lmdb_data', \n",
    "        resolution=64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sizes = sizes\n",
    "        self.resolution = resolution\n",
    "        imgs = ImageFolder(root_folder)\n",
    "        self._save_db(imgs, db_path)\n",
    "        self._db = lmdb.open(db_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def _save_db(self, files, db_path):\n",
    "        img_count = 0\n",
    "        db = lmdb.open(db_path, map_size=1024 ** 4)\n",
    "        with db.begin(write=True) as file:\n",
    "            for i, (original_img, _) in enumerate(files.imgs):\n",
    "                resize_imgs = self._resize_resolution(original_img)\n",
    "                for size, img in zip(self.sizes, resize_imgs):\n",
    "                    key = f'{size}-{str(i).zfill(5)}'\n",
    "                    file.put(key.encode('utf-8'), img)\n",
    "                img_count += 1\n",
    "            file.put('length'.encode('utf-8'), str(img_count).encode('utf-8'))\n",
    "            self._length = img_count\n",
    "        db.close()\n",
    "        \n",
    "    def _resize_resolution(self, img):\n",
    "        imgs = []\n",
    "        img = Image.open(img)\n",
    "        for size in self.sizes:\n",
    "            buffer = BytesIO()\n",
    "            img_resize = transforms.F.resize(img, size)\n",
    "            img_resize = transforms.F.center_crop(img_resize, size)\n",
    "            img_resize.save(buffer, format='jpeg')\n",
    "            imgs.append(buffer.getvalue())\n",
    "        return imgs\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        with self._db.begin(write=False) as file:\n",
    "            img_bytes = file.get(f'{self.resolution}-{str(index).zfill(5)}'.encode())\n",
    "        buffer = BytesIO(img_bytes)\n",
    "        img = Image.open(buffer)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __del__(self):\n",
    "        self._db.close()\n",
    "        \n",
    "    def show(self, index):\n",
    "        plt.imshow(self[index].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f2238",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6d89eac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T06:08:28.401210Z",
     "start_time": "2021-10-24T06:08:28.394947Z"
    }
   },
   "outputs": [],
   "source": [
    "class StyledGenerator(nn.Module):\n",
    "    def __init__(self, num_resolution, w_channel=512, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.mapping = MappingNetwork()\n",
    "        self.synthesis = SynthesisNetwork(num_resolution, w_channel=w_channel, device=device)\n",
    "\n",
    "    def forward(self, latent_code, level):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe52be",
   "metadata": {},
   "source": [
    "### Mapping Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8acdb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:36.243952Z",
     "start_time": "2021-10-24T05:21:36.232740Z"
    }
   },
   "outputs": [],
   "source": [
    "class MappingNetworkBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x))\n",
    "\n",
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, latent_in_dim=512, latent_out_dim=512, num_mlp=8, broadcast=18):\n",
    "        super().__init__()\n",
    "        self.latent_in_dim = latent_in_dim\n",
    "        self.broadcast = broadcast\n",
    "        self.norm = PixelNorm()\n",
    "        self._mapping = [MappingNetworkBlock(latent_in_dim, latent_out_dim) for i in range(num_mlp)]\n",
    "        self.mapping = nn.Sequential(*self._mapping)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = x.view(-1, self.latent_in_dim)\n",
    "        out = self.mapping(x)\n",
    "        out = out.unsqueeze(1)\n",
    "        return out.repeat(1, self.broadcast, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd8991",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cb7f1",
   "metadata": {},
   "source": [
    "#### FadeIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71160a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:37.720005Z",
     "start_time": "2021-10-24T05:21:37.711762Z"
    }
   },
   "outputs": [],
   "source": [
    "class FadeIn():\n",
    "    def __init__(self):\n",
    "        self.alpha = 1e-5\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        return x * (1 - self.alpha) + y * self.alpha\n",
    "    \n",
    "    def _update_alpha(self, delta):\n",
    "        self.alpha += abs(delta)\n",
    "        self.alpha = float(min(self.alpha, 1.))\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.alpha = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7836f",
   "metadata": {},
   "source": [
    "#### PixelNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f77827",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![pixelnorm](./source/20201215105113807.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d08ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:38.269303Z",
     "start_time": "2021-10-24T05:21:38.262943Z"
    }
   },
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self, sigma=1e-8):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x/√(x2_avg+ε)\n",
    "        return x.div(x.pow(2.).mean(dim=1, keepdim=True).add(self.sigma).sqrt()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82337c5",
   "metadata": {},
   "source": [
    "#### InstanceNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3928c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:38.628878Z",
     "start_time": "2021-10-24T05:21:38.622330Z"
    }
   },
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    def __init__(self, sigma=1e-8):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = (x-x_mean)/√(x2_avg+ε)\n",
    "        return (x - x.mean(dim=(2, 3), keepdim=True)).div(x.pow(2.).mean(dim=(2, 3), keepdims=True).add(self.sigma).sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fef99",
   "metadata": {},
   "source": [
    "#### ConstantInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c993a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:38.926249Z",
     "start_time": "2021-10-24T05:21:38.919318Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ConstantInput(nn.Module):\n",
    "    def __init__(self, channel=512, size=4):\n",
    "        super().__init__()\n",
    "        self.const_input = nn.Parameter(torch.randn(channel, size, size))\n",
    "    \n",
    "    def forward(self, batch_size):\n",
    "        out = self.const_input.repeat(batch_size, 1, 1, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990b9e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### AdaIn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315e7e2",
   "metadata": {},
   "source": [
    "![AdaIN](./source/AdaIN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820f2656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:39.415609Z",
     "start_time": "2021-10-24T05:21:39.406718Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, in_features=512, out_features=1024):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features, bias=True)\n",
    "    \n",
    "    def forward(self, x, w):\n",
    "        w = self.linear(w)\n",
    "        style = w.reshape([-1, 2, x.shape[1]] + [1] * (len(x.shape) - 2))\n",
    "        return x * (style[:, 0] + 1) + style[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc44f24",
   "metadata": {},
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33465b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:39.717492Z",
     "start_time": "2021-10-24T05:21:39.711522Z"
    }
   },
   "outputs": [],
   "source": [
    "class Noise(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "        # channel为每层输入的张量的通道数\n",
    "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        return noise * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c890ee",
   "metadata": {},
   "source": [
    "#### LayerEpilogue (每层最后都会有一个添加噪声和AdaIn的操作，这里定义一个LayerEpliogue进行封装)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed329350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:40.125351Z",
     "start_time": "2021-10-24T05:21:40.112072Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerEpilogue(nn.Module):\n",
    "    def __init__(self, layer_channel, w_channel=512, use_noise=True, use_pixel_norm=False, use_instance_norm=True, device='cpu'):\n",
    "        '''\n",
    "        :channel: x的通道数\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.use_noise = use_noise\n",
    "        self.B = Noise(layer_channel)\n",
    "        self.adain = AdaIN(w_channel, layer_channel*2)\n",
    "        \n",
    "        self.pixel_norm = PixelNorm()\n",
    "        self.instance_norm = InstanceNorm()\n",
    "        \n",
    "        self.use_pixel_norm = use_pixel_norm\n",
    "        self.use_instance_norm = use_instance_norm\n",
    "    \n",
    "    def forward(self, x, w, noise=None):\n",
    "        # 加入noise\n",
    "        if self.use_noise:\n",
    "            if noise is None:\n",
    "                noise = torch.randn([1, 1, x.shape[2], x.shape[3]], device=device)\n",
    "            x = x + self.B(noise)\n",
    "            \n",
    "        # 使用激活函数\n",
    "        \n",
    "        # 归一化处理    \n",
    "        if self.use_pixel_norm:\n",
    "            x = self.pixel_norm(x)\n",
    "        if self.use_instance_norm:\n",
    "            x = self.instance_norm(x)\n",
    "        \n",
    "        return self.adain(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56440c7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### StyleBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f2f289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:40.751051Z",
     "start_time": "2021-10-24T05:21:40.743188Z"
    }
   },
   "outputs": [],
   "source": [
    "class StyleBlock(nn.Module):\n",
    "    def __init__(self, resolution, w_channel=512, in_channels=512, out_channels=512, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert resolution >= 4\n",
    "        self.resolution = resolution\n",
    "        if resolution == 4:\n",
    "            self.constant_input = ConstantInput()\n",
    "        else:\n",
    "            self.upsample = nn.Upsample(scale_factor=2)\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self.layer_epilogue = LayerEpilogue(layer_channel=out_channels, w_channel=w_channel, device=device)\n",
    "        \n",
    "    def forward(self, w, x=None, noises=None):\n",
    "        if self.resolution == 4:\n",
    "            x = self.constant_input(w[0].shape[0])\n",
    "        else:\n",
    "            assert x is not None\n",
    "            x = self.lrelu(self.conv1(self.upsample(x)))\n",
    "        x = self.layer_epilogue(x, w[0], noises[0])\n",
    "        x = self.lrelu(self.conv2(x))\n",
    "        x = self.layer_epilogue(x, w[1], noises[1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24067b",
   "metadata": {},
   "source": [
    "#### MinibatchStddevLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ff8db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:41.232090Z",
     "start_time": "2021-10-24T05:21:41.223468Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinibatchStdDev(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, alpha=1e-8):\n",
    "        batch_size, _, height, width = x.shape\n",
    "        y = x - x.mean(dim=0, keepdim=True)\n",
    "        y = torch.sqrt(y.pow(2.).mean(dim=0, keepdim=False) + alpha)\n",
    "        y = y.mean().view(1, 1, 1, 1)\n",
    "        y = y.repeat(batch_size, 1, height, width)\n",
    "        y = torch.cat([x, y], 1)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2409a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### SynthesisNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7052d873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:42.195918Z",
     "start_time": "2021-10-24T05:21:42.160700Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SynthesisNetwork(nn.Module):\n",
    "    def __init__(self, num_resolution, w_channel=512, device='cpu'):\n",
    "        super().__init__()\n",
    "        max_channel = 512\n",
    "\n",
    "        # 生成 noises\n",
    "        self.noises = []\n",
    "        self._generate_noise(num_resolution, device)\n",
    "        \n",
    "        self.style, self.to_rgb = nn.ModuleDict(), nn.ModuleList()\n",
    "        for resolution_idx in range(num_resolution):\n",
    "            resolution = np.power(2, (resolution_idx + 2))\n",
    "            if 4 <= resolution <= 32:\n",
    "                self.style[f'res{resolution}'] = StyleBlock(resolution,\n",
    "                                                            w_channel=w_channel,\n",
    "                                                            in_channels=max_channel, \n",
    "                                                            out_channels=max_channel,\n",
    "                                                            device=device)\n",
    "                self.to_rgb.append(self._to_rgb(max_channel))\n",
    "            else:\n",
    "                self.style[f'res{resolution}'] = StyleBlock(resolution, \n",
    "                                                            w_channel=w_channel,\n",
    "                                                            in_channels=max_channel//np.power(2, resolution_idx-4), \n",
    "                                                            out_channels=max_channel//np.power(2, resolution_idx-3),\n",
    "                                                            device=device)\n",
    "                self.to_rgb.append(self._to_rgb(max_channel//np.power(2, resolution_idx-3)))\n",
    "                \n",
    "        self.fade_in = FadeIn()\n",
    "        \n",
    "    def forward(self, w, level):\n",
    "        # level是指第level个block 4：0，8：1...\n",
    "        resolution = np.power(2, level + 2)\n",
    "        x = None\n",
    "        for block_idx, block in enumerate(self.style.values()):\n",
    "            if block_idx < level:\n",
    "                x = block([w[:, block_idx * 2, :], w[:, block_idx * 2 + 1, :]], \n",
    "                          x, \n",
    "                          [self.noises[block_idx * 2], self.noises[block_idx * 2 + 1]])\n",
    "                \n",
    "        if level == 0:\n",
    "            x = self.style[f'res{resolution}']((w[:, level * 2, :], w[:, level * 2 + 1, :]), \n",
    "                                                x, \n",
    "                                               (self.noises[level * 2], self.noises[level * 2 + 1]))\n",
    "            \n",
    "            x = self.to_rgb[level](x)\n",
    "            return x\n",
    "        \n",
    "        residual = x.clone()\n",
    "        \n",
    "        residual = F.interpolate(x, scale_factor=2)\n",
    "        residual = self.to_rgb[level-1](residual)\n",
    "        x = self.style[f'res{resolution}']((w[:, level * 2, :], w[:, level * 2 + 1, :]), \n",
    "                                            x, \n",
    "                                           (self.noises[level * 2], self.noises[level * 2 + 1]))\n",
    "        x = self.to_rgb[level](x)\n",
    "        return self.fade_in(residual, x)\n",
    "\n",
    "    \n",
    "    def _generate_noise(self, num_resolution, device='cpu'):\n",
    "        for layer_idx in range(1, (num_resolution) * 2 + 1):\n",
    "            self.noises.append(torch.randn([1, 1, 2 ** ((layer_idx + 1) // 2 + 1), 2 ** ((layer_idx + 1) // 2 + 1)], device=device))\n",
    "    \n",
    "    def _to_rgb(self, in_channels):\n",
    "        return nn.Conv2d(in_channels, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0880aa",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3cce02",
   "metadata": {},
   "source": [
    "#### DiscriminatorBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155c95eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:47.085108Z",
     "start_time": "2021-10-24T05:21:47.072863Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, resolution, in_channels=512, out_channels=512):\n",
    "        super().__init__()\n",
    "        assert resolution >= 4\n",
    "        self.resolution = resolution\n",
    "        \n",
    "        if resolution == 4:\n",
    "            self.model = nn.Sequential(\n",
    "                MinibatchStdDev(), \n",
    "                nn.Conv2d(in_channels+1, out_channels, kernel_size=4),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Flatten(),  # 全连接之前将张量展平\n",
    "                nn.Linear(out_channels, out_channels),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Linear(out_channels, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1), \n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.AvgPool2d(2)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ae02931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:21:47.731082Z",
     "start_time": "2021-10-24T05:21:47.719545Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_resolution):\n",
    "        super().__init__()\n",
    "        self.num_resolution = num_resolution\n",
    "        max_channel = 512\n",
    "        \n",
    "        self.model, self.from_rgb = nn.ModuleDict(), nn.ModuleList()\n",
    "        for resolution_idx in range(num_resolution - 1, -1, -1):\n",
    "            resolution = np.power(2, (resolution_idx + 2))\n",
    "            if 4 <= resolution <= 32:\n",
    "                self.model[f'resolution{resolution}'] = DiscriminatorBlock(resolution, max_channel, max_channel)\n",
    "                self.from_rgb.append(self._from_rgb(max_channel))\n",
    "            else:\n",
    "                self.model[f'resolution{resolution}'] = DiscriminatorBlock(resolution, \n",
    "                                                                           max_channel//np.power(2, resolution_idx-3), \n",
    "                                                                           max_channel//np.power(2, resolution_idx-4))\n",
    "                self.from_rgb.append(self._from_rgb(max_channel//np.power(2, resolution_idx-3)))\n",
    "        \n",
    "        self.fade_in = FadeIn()\n",
    "        \n",
    "    def forward(self, x, level):\n",
    "        resolution = np.power(2, level + 2)\n",
    "        residual = x.clone()\n",
    "        x = self.from_rgb[self.num_resolution-level-1](x)\n",
    "        \n",
    "        if level == 0:\n",
    "            x = self.model[f'resolution{resolution}'](x)\n",
    "            return x.view(-1)\n",
    "        \n",
    "        residual = F.avg_pool2d(residual, kernel_size=2, stride=2)\n",
    "        residual = self.from_rgb[self.num_resolution-level](residual)\n",
    "        x = self.model[f'resolution{resolution}'](x)\n",
    "        x = self.fade_in(residual, x)\n",
    "        for block_idx, block in enumerate(self.model.values()):\n",
    "            if block_idx >= (self.num_resolution - level):\n",
    "                x = block(x)\n",
    "        return x.view(-1)\n",
    "    \n",
    "    \n",
    "    def _from_rgb(self, out_channels):\n",
    "        return nn.Conv2d(3, out_channels=out_channels, kernel_size=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7607b6",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d575574e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T06:16:03.765113Z",
     "start_time": "2021-10-24T06:16:03.749069Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, G, D):\n",
    "        self.G = G\n",
    "        self.D = D\n",
    "        \n",
    "        \n",
    "class WGAN(Loss):\n",
    "    def __init__(self, G, D, wgan_epsilon=0.001, wgan_lambda=10.0, wgan_target=1.0, device='cpu'):\n",
    "        super().__init__(G, D)\n",
    "        self.device = device\n",
    "        self.wgan_epsilon = wgan_epsilon\n",
    "        self.wgan_lambda = wgan_lambda\n",
    "        self.wgan_target = wgan_target\n",
    "        if device.type == 'cuda':\n",
    "            self.G = self.G.module\n",
    "            self.D = self.D.module\n",
    "\n",
    "    def G_wgan(self, latent_code, level):\n",
    "        # Loss_G = -D(G(z))\n",
    "        w = self.G.mapping(latent_code)\n",
    "        fake_images = self.G.synthesis(w, level)\n",
    "        fake_out = self.D(fake_images, level)\n",
    "        loss = -torch.mean(fake_out)\n",
    "        return loss, fake_images\n",
    "    \n",
    "    def D_wgan(self, latent_code, real_images, level):\n",
    "        # Loss_D = D(G(z)) - D(x) + ε·D(x)^2\n",
    "        w = self.G.mapping(latent_code)\n",
    "        fake_images = self.G.synthesis(w, level)\n",
    "        real_out = self.D(real_images, level)\n",
    "        fake_out = self.D(fake_images, level)\n",
    "        loss = torch.mean(fake_out) - torch.mean(real_out) + self.wgan_epsilon * torch.square(real_out)\n",
    "        return loss, fake_images\n",
    "    \n",
    "    def D_wgan_gp(self, latent_code, real_images, level):\n",
    "        # Loss_D = D(G(z)) - D(x) + η·(||∇T||-1)^2 + ε·D(x)^2\n",
    "        # D(G(z)) - D(x) + ε·D(x)^2\n",
    "        wgan_loss, fake_images = self.D_wgan(latent_code, real_images, level)\n",
    "        \n",
    "        # η·(||∇T||-1)^2  梯度惩罚\n",
    "        alpha = torch.rand(latent_code.shape[0], 1, 1, 1).uniform_(-1, 1).to(self.device)\n",
    "        interpolates = real_images.data * alpha + (1 - alpha) * fake_images.data  # 真实分布与生成分布之间的插值\n",
    "        interpolates.requires_grad = True\n",
    "        interpolates_pred = self.D(interpolates, level)\n",
    "        gradients = torch.autograd.grad(outputs=interpolates_pred.sum(), inputs=interpolates, create_graph=True)[0] # 求梯度\n",
    "        slopes = torch.sqrt(torch.sum(torch.square(gradients), dim=(1, 2, 3)))# 取模\n",
    "        gradient_penalty = (self.wgan_lambda / self.wgan_target ** 2) * torch.mean((slopes - self.wgan_target)**2)\n",
    "        return (wgan_loss + gradient_penalty).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b71646",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "17d74e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T06:41:16.110471Z",
     "start_time": "2021-10-24T06:41:16.083253Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TrainProcessing:\n",
    "    def __init__(self, \n",
    "                 dataset,\n",
    "                 epoch = 800_000,\n",
    "                 latent_code_dim = 512,\n",
    "                 num_resolution = 5,\n",
    "                 batch_size = 16,\n",
    "                 num_gpu = 4,\n",
    "                 beta1 = 0.5,\n",
    "                 init_size = 4,\n",
    "                 max_size = 64,\n",
    "                 wgan_epsilon=0.001, \n",
    "                 wgan_lambda=10.0, \n",
    "                 wgan_target=1.0\n",
    "                ):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        # 图像尺寸训练范围\n",
    "        self.init_size = init_size\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        # 超参数设置\n",
    "        self.epoch = epoch\n",
    "        self.latent_code_dim = latent_code_dim\n",
    "        self.num_resolution = num_resolution\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # gpu\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.num_gpu = num_gpu\n",
    "        IS_PARALLEL = True if num_gpu > 1 else False\n",
    "\n",
    "        self.generator = StyledGenerator(num_resolution=num_resolution, w_channel=latent_code_dim, device=self.device)\n",
    "        self.discriminator = Discriminator(num_resolution=num_resolution)\n",
    "        \n",
    "        if IS_PARALLEL and torch.cuda.device_count() > 1:\n",
    "            self.generator = nn.DataParallel(self.generator, device_ids=range(num_gpu)).cuda()\n",
    "            self.discriminator = nn.DataParallel(self.discriminator, device_ids=range(num_gpu)).cuda()\n",
    "        \n",
    "#         self.generator = self.generator.to(self.device)\n",
    "#         self.discriminator = self.discriminator.to(self.device)\n",
    "\n",
    "        # 优化器\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002, betas=(beta1, 0.999))\n",
    "        self.discriminator_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(beta1, 0.999))\n",
    "\n",
    "        # 初始化损失函数\n",
    "        self.loss = WGAN(self.generator, self.discriminator, device=self.device)\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        level = int(math.log2(self.init_size)) - 2\n",
    "        resolution = 4 * 2 ** level\n",
    "        \n",
    "        train_loader = self._sample_data(self.dataset, resolution, self.batch_size)\n",
    "        data_loader = iter(train_loader)\n",
    "        \n",
    "        loss_dict = {\n",
    "            'disc_loss_val': 0,\n",
    "            'gen_loss_val': 0,\n",
    "        }\n",
    "        \n",
    "        used_sample = 0\n",
    "        phase = 60_000\n",
    "        \n",
    "        pbar = tqdm.tqdm(range(self.epoch))\n",
    "        \n",
    "        max_level = int(math.log2(self.max_size)) - 2\n",
    "        final_progress = False\n",
    "        \n",
    "        for iteration in pbar:\n",
    "            alpha = min(1, 1 / phase * (used_sample + 1))\n",
    "            \n",
    "            if used_sample > phase * 2:\n",
    "                used_sample = 0\n",
    "                level += 1\n",
    "\n",
    "                if level > max_level:\n",
    "                    level = max_level\n",
    "                    final_progress = True\n",
    "                else:\n",
    "                    self._update_alpha(1)\n",
    "                    \n",
    "                ckpt_level = level\n",
    "\n",
    "                resolution = 4 * 2 ** level\n",
    "\n",
    "                train_loader = self._sample_data(self.dataset, resolution, self.batch_size)\n",
    "                data_loader = iter(train_loader)\n",
    "\n",
    "                self._save_model(ckpt_level)\n",
    "\n",
    "            try:\n",
    "                data = next(data_loader)\n",
    "            except StopIteration:\n",
    "                data_loader = iter(train_loader)\n",
    "                data = next(data_loader)\n",
    "                \n",
    "            real_images = data.to(self.device)\n",
    "            used_sample += real_images.shape[0]\n",
    "\n",
    "            # 训练判别器\n",
    "            self._requires_grad(self.generator, False)\n",
    "            self._requires_grad(self.discriminator, True)\n",
    "\n",
    "            latent = torch.randn(self.batch_size, self.latent_code_dim, 1, 1, device=self.device)\n",
    "            # 计算损失\n",
    "            d_loss = self.loss.D_wgan_gp(latent, real_images, level)\n",
    "            self.discriminator.zero_grad()\n",
    "            d_loss.backward()\n",
    "            self.discriminator_optimizer.step()\n",
    "            \n",
    "            loss_dict['disc_loss_val'] = d_loss.item()\n",
    "\n",
    "            # 训练生成器\n",
    "            self._requires_grad(self.generator, True)\n",
    "            self._requires_grad(self.discriminator, False)\n",
    "\n",
    "            latent = torch.randn(self.batch_size, self.latent_code_dim, 1, 1, device=self.device)\n",
    "            g_loss, _ = self.loss.G_wgan(latent, level)\n",
    "            \n",
    "            loss_dict['gen_loss_val'] = g_loss.item()\n",
    "\n",
    "            self.generator.zero_grad()\n",
    "            g_loss.backward()\n",
    "            self.generator_optimizer.step()\n",
    "            \n",
    "            self._requires_grad(self.generator, False)\n",
    "            self._requires_grad(self.discriminator, True)\n",
    "            \n",
    "            # 设置print内容\n",
    "            state_msg = (\n",
    "                f'Size: {4 * 2 ** level}; G: {loss_dict[\"gen_loss_val\"]:.3f}; D: {loss_dict[\"disc_loss_val\"]:.3f};'\n",
    "                f' Alpha: {alpha:.5f}'\n",
    "            )\n",
    "            pbar.set_description(state_msg)\n",
    "    \n",
    "    def _requires_grad(self, model, flag=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = flag\n",
    "            \n",
    "    def _sample_data(self, dataset, resolution, batch_size):\n",
    "        dataset.resolution = resolution\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    def _update_alpha(self, alpha):\n",
    "        if self.device.type == 'cuda':\n",
    "            self.generator.module.synthesis.fade_in.alpha = alpha\n",
    "            self.discriminator.module.fade_in.alpha = alpha\n",
    "        else:\n",
    "            self.generator.synthesis.fade_in.alpha = alpha\n",
    "            self.discriminator.module.fade_in.alpha = alpha\n",
    "        \n",
    "    def _save_model(self, ckpt_level):\n",
    "        if self.num_gpu > 0:\n",
    "            g = self.generator.module\n",
    "            d = self.discriminator.module\n",
    "        else:\n",
    "            g = self.generator\n",
    "            d = self.discriminator\n",
    "        \n",
    "        torch.save(\n",
    "            {\n",
    "                'generator': g.state_dict(),\n",
    "                'discriminator': d.state_dict(),\n",
    "                'g_optimizer': self.generator_optimizer.state_dict(),\n",
    "                'd_optimizer': self.discriminator_optimizer.state_dict(),\n",
    "            },\n",
    "            f'checkpoint/train_step-{ckpt_level}.model',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e7c46b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T06:16:53.425708Z",
     "start_time": "2021-10-24T06:16:28.909092Z"
    }
   },
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "#         transforms.Resize(64),\n",
    "#         transforms.CenterCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = AnimeFace(root_folder='/amax/data/LHao/dataset/', transform=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0708374",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-24T06:41:20.451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 64; G: -35841.098; D: 948020.375; Alpha: 1.00000:   4%|▍         | 34430/800000 [1:09:47<85:11:04,  2.50it/s]        "
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1, 2, 3'\n",
    "trainer = TrainProcessing(dataset)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "notebook/GAN/stylegan/stylegan.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "739px",
    "left": "1099.2px",
    "top": "359px",
    "width": "223.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 426,
   "position": {
    "height": "40px",
    "left": "1397px",
    "right": "20px",
    "top": "121px",
    "width": "509px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
